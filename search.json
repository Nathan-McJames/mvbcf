[{"path":"https://nathan-mcjames.github.io/mvbcf/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 mvbcf authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://nathan-mcjames.github.io/mvbcf/articles/full-guide.html","id":"creating-synthetic-data","dir":"Articles","previous_headings":"","what":"Creating Synthetic Data","title":"Full Guide","text":"Let’s start creating synthetic data. example imagine observational data school students, want determine participation optional -school tutoring lessons impact test scores mathematics English. Let’s also assume data important characteristics students age, gender, previous test-scores, education level income parents. make data-generating-process semi-realistic, let’s assume students lower test scores might likely take part school tuition order increase grades. Let’s also assume students high earning families might able afford extra tuition. ’ll say probability attending extra lessons directly related average previous test score, students family income greater 70000 can afford . new maths English scores year taking part/taking part extra tuition, reasonable imagine following: new maths/English score usually higher previous score students learning Students highly educated wealthy parents may learned due extra educational resources home Students received extra tuition increased test scores students Older students benefit extra tuition better developed concentration study skills Ok! data ready! Let’s create dataframe: present, run_mvbcf() function requires covariates numeric features. Therefore, proceeding, need convert factor variables (gender parent_education) numeric variables. Gender clear ordering, use simple dummy variable (0=female, 1=male) Parent_education ordering say (1=school, 2=bachelors, 3=masters) , can create matrix covariates X, outcome matrix Y, treatment indicator Z.","code":"set.seed(101)  n<-1000  age<-runif(n, 11, 12) gender<-sample(c(\"Male\", \"Female\"), n, replace=T) previous_maths_score<-rnorm(n, 0.4, 0.08) previous_english_score<-rnorm(n, 0.4, 0.08) parent_education<-sample(c(\"School\", \"Bachelors\", \"Masters\"), n,                           replace=T, prob=c(0.5, 0.25, 0.25)) parent_income<-rnorm(n, 60000, 10000)  ############################# ##Same format for test data## #############################  n_test<-1000  age_test<-runif(n_test, 11, 12) gender_test<-sample(c(\"Male\", \"Female\"), n_test, replace=T) previous_maths_score_test<-rnorm(n_test, 0.4, 0.08) previous_english_score_test<-rnorm(n_test, 0.4, 0.08) parent_education_test<-sample(c(\"School\", \"Bachelors\", \"Masters\"), n_test,                                replace=T, prob=c(0.5, 0.25, 0.25)) parent_income_test<-rnorm(n_test, 60000, 10000) true_propensity<-1-0.5*(previous_maths_score+previous_english_score)*(parent_income>70000)  extra_tuition<-rbinom(n, 1, true_propensity)  ############################# ##Same format for test data## #############################  true_propensity_test<-1-0.5*(previous_maths_score_test+previous_english_score_test) true_propensity_test<-true_propensity_test*(parent_income_test>70000)   extra_tuition_test<-rbinom(n_test, 1, true_propensity_test) new_maths_score<-previous_maths_score+                   0.05+                   0.05*(parent_education %in% c(\"Bachelors\", \"Masters\"))+                   (parent_income/2000000)+                   extra_tuition*0.1*(age-11)+                   rnorm(n, 0, 0.1)  #Note that this means the treatment effect is given by: icate_maths<-0.1*(age-11)   new_english_score<-previous_english_score+                   0.07+                   0.03*(parent_education %in% c(\"Bachelors\", \"Masters\"))+                   (parent_income/2500000)+                   extra_tuition*0.12*(age-11)+                   rnorm(n, 0, 0.1)  #Note that this means the treatment effect is given by: icate_english<-0.12*(age-11)  ############################# ##Same format for test data## #############################  new_maths_score_test<-previous_maths_score_test+                   0.05+                   0.05*(parent_education_test %in% c(\"Bachelors\", \"Masters\"))+                   (parent_income_test/2000000)+                   extra_tuition_test*0.1*(age_test-11)+                   rnorm(n_test, 0, 0.1)  #Note that this means the treatment effect is given by: icate_maths_test<-0.1*(age_test-11)   new_english_score_test<-previous_english_score_test+                   0.07+                   0.03*(parent_education_test %in% c(\"Bachelors\", \"Masters\"))+                   (parent_income_test/2500000)+                   extra_tuition_test*0.12*(age_test-11)+                   rnorm(n_test, 0, 0.1)  #Note that this means the treatment effect is given by: icate_english_test<-0.12*(age_test-11) df<-as.data.frame(cbind(age,                         gender,                         previous_maths_score,                         previous_english_score,                         parent_education,                         parent_income,                         extra_tuition,                         new_maths_score,                         new_english_score))  ############################# ##Same format for test data## #############################  df_test<-as.data.frame(cbind(age_test,                         gender_test,                         previous_maths_score_test,                         previous_english_score_test,                         parent_education_test,                         parent_income_test,                         extra_tuition_test,                         new_maths_score_test,                         new_english_score_test)) df$gender<-ifelse(df$gender==\"Female\", 0, 1)  education_map<-list(\"School\"=1, \"Bachelors\"=2, \"Masters\"=3)  df$parent_education<-as.numeric(education_map[parent_education])  ############################# ##Same format for test data## #############################  df_test$gender_test<-ifelse(df_test$gender_test==\"Female\", 0, 1)  df_test$parent_education_test<-as.numeric(education_map[parent_education_test]) df$age<-as.numeric(df$age) df$previous_maths_score<-as.numeric(df$previous_maths_score) df$previous_english_score<-as.numeric(df$previous_english_score) df$parent_income<-as.numeric(df$parent_income)  X<-as.matrix(df[,c(\"age\", \"gender\", \"previous_maths_score\",                     \"previous_english_score\", \"parent_education\",                     \"parent_income\")])   df$new_maths_score<-as.numeric(df$new_maths_score) df$new_english_score<-as.numeric(df$new_english_score)  y<-as.matrix(df[,c(\"new_maths_score\", \"new_english_score\")])  df$extra_tuition<-as.numeric(df$extra_tuition)  Z<-df$extra_tuition  ############################# ##Same format for test data## #############################  df_test$age_test<-as.numeric(df_test$age_test) df_test$previous_maths_score_test<-as.numeric(df_test$previous_maths_score_test) df_test$previous_english_score_test<-as.numeric(df_test$previous_english_score_test) df_test$parent_income_test<-as.numeric(df_test$parent_income_test)  X_test<-as.matrix(df_test[,c(\"age_test\", \"gender_test\", \"previous_maths_score_test\",                     \"previous_english_score_test\", \"parent_education_test\",                     \"parent_income_test\")])   df_test$new_maths_score_test<-as.numeric(df_test$new_maths_score_test) df_test$new_english_score_test<-as.numeric(df_test$new_english_score_test)  y_test<-as.matrix(df_test[,c(\"new_maths_score_test\", \"new_english_score_test\")])  df_test$extra_tuition_test<-as.numeric(df_test$extra_tuition_test)  Z_test<-df_test$extra_tuition_test"},{"path":"https://nathan-mcjames.github.io/mvbcf/articles/full-guide.html","id":"fitting-the-model","dir":"Articles","previous_headings":"","what":"Fitting The Model","title":"Full Guide","text":"data prepared, time fit model data. X_con, y, Z, X_mod parameters required parameters hyper-parameters default settings, look . X_con matrix covariates used creating decision rules μ\\mu trees model. include variables wish control confounding variables. nn rows corresponding nn observations, pp columns corresponding control variables. y matrix outcome variables. nn rows column correspond unique outcome variable. Z treatment indicator. vector length nn, 0 ithi^{th} position indicating observation ii receive treatment. 1 indicates observation ii receive treatment. X_mod matrix covariates used τ\\tau trees model. include variables believe may responsible modifying effect treatment. X_con_test X_mod_test covariate matrices control moderation variables test data. alpha beta BART tree priors used μ\\mu trees. Defaults alpha=0.95 beta=2. Lower alpha values higher beta values lead greater regularisation μ\\mu trees. alpha_tau beta_tau BART tree priors used τ\\tau trees. Defaults alpha_tau=0.25 beta_tau=3. Lower alpha_tau values higher beta_tau values lead greater regularisation τ\\tau trees. sigma_mu prior covariance matrix terminal node parameters μ\\mu trees model. sigma_tau prior covariance matrix terminal node parameters τ\\tau trees model. v_0 prior degrees freedom inverse-wishart distribution. sigma_0 scale matrix prior inverse-wishart distribution. n_iter number MCMC iterations model run . default 1000 may need increased depending quick model converge data. n_tree number trees used μ\\mu part model. trees allow model flexibly capture complex patterns non-linear relationships interaction terms among confounding variables X_con. n_tree_tau number trees used τ\\tau part model. trees allow model flexibly capture complex patterns non-linear relationships interaction terms among effect moderators X_mod. min_nodesize least number observations allowed terminal node. Tree moves resulting terminal nodes fewer observations automatically rejected.","code":"#Load the mvbcf package library(mvbcf)     mvbcf_mod <- run_mvbcf(X,                     y,                     Z,                     X,                     X_test,                     X_test,                     alpha = 0.95,                     beta = 2,                     alpha_tau = 0.25,                     beta_tau = 3,                     sigma_mu = diag((1)^2/50, ncol(y)),                     sigma_tau = diag((1)^2/20, ncol(y)),                     v_0 = ncol(y)+2,                     sigma_0 = diag(1, ncol(y)),                     n_iter = 1000,                     n_tree = 50,                     n_tree_tau = 20,                     min_nodesize = 1)"},{"path":"https://nathan-mcjames.github.io/mvbcf/articles/full-guide.html","id":"model-output---sigmas","dir":"Articles","previous_headings":"","what":"Model Output - sigmas","title":"Full Guide","text":"sigmas output model contains posterior residual covariance matrix. dimension sigmas ncol(y)*ncol(y)*n_iter. inspect posterior jthj^{th} outcome variable, Σj,j\\Sigma_{j,j}, residual covariance outcome variables jj kk, Σj,j\\Sigma_{j,j}, see code .","code":"#Look at posterior of residual variance of outcome 1 plot(mvbcf_mod$sigmas[1,1,], type=\"l\",       main=\"Sigma11 Samples - 1st Outcome Variable\",      ylab=\"Samples\") #Look at posterior of residual covariance of outcome 1 and outcome 2 plot(mvbcf_mod$sigmas[1,2,], type=\"l\",       main=\"Sigma12 Samples - Residual Covariance of 1st and 2nd Outcomes\",      ylab=\"Samples\")"},{"path":"https://nathan-mcjames.github.io/mvbcf/articles/full-guide.html","id":"model-output---predictions-and-predictions_test","dir":"Articles","previous_headings":"","what":"Model Output - predictions and predictions_test","title":"Full Guide","text":"predictions output model contains posterior individual level μ\\mu predictions individual. dimension predictions nrow(y)*ncol(y)*n_iter. predictions_test output contains output test data provided. inspect posterior μ\\mu predictions jthj^{th} outcome variable associated individual ii, obtain posterior mean μ\\mu predictions different individuals can use following code.","code":"#Look at mu posterior of outcome 2 for individual 23 hist(mvbcf_mod$predictions[23,2,],      xlab=\"Posterior Samples\",      main=\"Posterior of mu Predictions for Specific Individual\") #get posterior mean of mu predictions for all observations mu1_preds<-rowMeans(mvbcf_mod$predictions[,1,]) mu2_preds<-rowMeans(mvbcf_mod$predictions[,2,])  #If you want to remove some samples as burn-in you can do the following instead mu1_preds<-rowMeans(mvbcf_mod$predictions[,1,-c(1:500)]) mu2_preds<-rowMeans(mvbcf_mod$predictions[,2,-c(1:500)])"},{"path":"https://nathan-mcjames.github.io/mvbcf/articles/full-guide.html","id":"model-output---predictions_tau-and-predictions_tau_test","dir":"Articles","previous_headings":"","what":"Model Output - predictions_tau and predictions_tau_test","title":"Full Guide","text":"predictions_tau output model contains posterior individual conditional average treatment effect τ\\tau predictions individual. dimension predictions_tau nrow(y)*ncol(y)*n_iter. predictions_tau_test output contains output test data provided. inspect posterior τ\\tau predictions jthj^{th} outcome variable associated individual ii, obtain posterior mean τ\\tau predictions different individuals can use following code. Often, may interested average treatment effect - show find well.","code":"#Look at icate posterior of outcome 2 for individual 23 hist(mvbcf_mod$predictions_tau[23,2,],      xlab=\"Posterior Samples\",      main=\"Posterior of tau Predictions for Specific Individual\") #get posterior mean of tau icate predictions for all observations tau1_preds<-rowMeans(mvbcf_mod$predictions_tau[,1,]) tau2_preds<-rowMeans(mvbcf_mod$predictions_tau[,2,])  #If you want to remove some samples as burn-in you can do the following instead tau1_preds<-rowMeans(mvbcf_mod$predictions_tau[,1,-c(1:500)]) tau2_preds<-rowMeans(mvbcf_mod$predictions_tau[,2,-c(1:500)])  #To get the average treatment effect posterior for outcome 1 ate1_post<-colMeans(mvbcf_mod$predictions_tau[,1,-c(1:500)])  #To get the average treatment effect posterior for outcome 2 ate2_post<-colMeans(mvbcf_mod$predictions_tau[,2,-c(1:500)])   #Look at density plots of ATE posteriors plot(density(ate1_post), xlab=\"ATE Outcome 1\", main=\"Posterior of ATE for Outcome 1\") plot(density(ate2_post), xlab=\"ATE Outcome 2\", main=\"Posterior of ATE for Outcome 2\")"},{"path":"https://nathan-mcjames.github.io/mvbcf/articles/full-guide.html","id":"comparing-predictions-with-ground-truth","dir":"Articles","previous_headings":"","what":"Comparing Predictions With Ground Truth","title":"Full Guide","text":"provide two examples checking well yy predictions unseen test data compare ground truth, well treatment effect predictions unseen test data compare ground truth.","code":"y1_test_preds<-rowMeans(mvbcf_mod$predictions_test[,1,]+Z_test*mvbcf_mod$predictions_tau_test[,1,]) y2_test_preds<-rowMeans(mvbcf_mod$predictions_test[,2,]+Z_test*mvbcf_mod$predictions_tau_test[,2,])  icate_maths_test_predictions<-rowMeans(mvbcf_mod$predictions_tau_test[,1,]) icate_english_test_predictions<-rowMeans(mvbcf_mod$predictions_tau_test[,2,])  plot(new_maths_score_test, y1_test_preds,       xlab=\"True Mathematics Score\",      ylab=\"Predicted Mathematics Score\",      main=\"Predicted vs. True Values\") abline(0, 1) y1_test_residuals<-new_maths_score_test-y1_test_preds qqnorm(y1_test_residuals) qqline(y1_test_residuals) plot(icate_maths_test, icate_maths_test_predictions,       xlab=\"True Mathematics Effect\",      ylab=\"Predicted Mathematics Effect\",      main=\"Predicted vs. True Values\") abline(0, 1)"},{"path":"https://nathan-mcjames.github.io/mvbcf/articles/quick-start.html","id":"fitting-the-model","dir":"Articles","previous_headings":"","what":"Fitting The Model","title":"Quick-Start Guide","text":"","code":"#Load the mvbcf package library(mvbcf)  #set seed set.seed(101)  #Create some synthetic data #number of observations n<-500 #number of covariates p<-5  #matrix of covariates X<-matrix(runif(n*p), nrow=n)  #The outcome under control for y1 and y2 mu1<-3*X[,1]-4*X[,3]^2 mu2<-4*X[,1]+1*X[,3]^2-2*X[,5]  #The effect of receiving treatment on y1 and y2 tau1<-1*X[,1] tau2<-0.6*X[,1]  #The probability of receiving treatment (true propensity score) true_propensity<-(X[,2]+X[,3])/3  #Treatment status Z<-rbinom(n, 1, true_propensity)  #The observed outcomes y1<-mu1+Z*tau1+rnorm(n, 0, 1) y2<-mu2+Z*tau2+rnorm(n, 0, 1)  Y<-cbind(y1, y2)  mvbcf_mod <- run_mvbcf(X,                        Y,                        Z,                        X)"},{"path":"https://nathan-mcjames.github.io/mvbcf/articles/quick-start.html","id":"check-convergence","dir":"Articles","previous_headings":"","what":"Check Convergence","title":"Quick-Start Guide","text":"Quick look convergence posterior Σ1,1\\Sigma_{1,1} Σ2,2\\Sigma_{2,2} (residual variance corresponding outcome variables y1y_{1} y2y_{2}).","code":"plot(mvbcf_mod$sigmas[1,1,], type=\"l\", ylab=\"Sigma11 Samples\") plot(mvbcf_mod$sigmas[2,2,], type=\"l\", ylab=\"Sigma22 Samples\")"},{"path":"https://nathan-mcjames.github.io/mvbcf/articles/quick-start.html","id":"look-at-average-treatment-effect-ate-posterior","dir":"Articles","previous_headings":"","what":"Look at Average Treatment Effect (ATE) Posterior","title":"Quick-Start Guide","text":"Histogram posterior samples ATE (Average Treatment Effect) y1y_{1} y2y_{2}.","code":"hist(colMeans(mvbcf_mod$predictions_tau[,1,]),      xlab=\"Tau1 ATE Samples\",      main=\"Histogram of Posterior Samples\") hist(colMeans(mvbcf_mod$predictions_tau[,2,]),      xlab=\"Tau2 ATE Samples\",      main=\"Histogram of Posterior Samples\")"},{"path":"https://nathan-mcjames.github.io/mvbcf/articles/quick-start.html","id":"look-at-model-predictions","dir":"Articles","previous_headings":"","what":"Look at Model Predictions","title":"Quick-Start Guide","text":"Get predicted μ\\mu, τ\\tau, yy predictions, compare ground truth.","code":"mu1_preds<-rowMeans(mvbcf_mod$predictions[,1,]) mu2_preds<-rowMeans(mvbcf_mod$predictions[,2,])  tau1_preds<-rowMeans(mvbcf_mod$predictions_tau[,1,]) tau2_preds<-rowMeans(mvbcf_mod$predictions_tau[,2,])  y1_preds<-rowMeans(mvbcf_mod$predictions[,1,]+Z*mvbcf_mod$predictions_tau[,1,]) y2_preds<-rowMeans(mvbcf_mod$predictions[,2,]+Z*mvbcf_mod$predictions_tau[,2,])   plot(mu1, mu1_preds, main=\"Predicted vs. True Values\", xlab=\"Mu1\", ylab=\"Mu1 Predictions\") abline(0,1) plot(tau1, tau1_preds, main=\"Predicted vs. True Values\", xlab=\"Tau1\", ylab=\"Tau1 Predictions\") abline(0,1) plot(y1, y1_preds, main=\"Predicted vs. True Values\", xlab=\"y1\", ylab=\"y1 Predictions\") abline(0,1) y1_residuals<-y1-y1_preds qqnorm(y1_residuals) qqline(y1_residuals)"},{"path":"https://nathan-mcjames.github.io/mvbcf/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Nathan-McJames. Maintainer.","code":""},{"path":"https://nathan-mcjames.github.io/mvbcf/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"McJames N, O'Shea , Goh YC, Parnell (2024). mvbcf: R Package Implementing Multivariate Bayesian Causal Forests. R package version 1.0, https://nathan-mcjames.github.io/mvbcf/.","code":"@Manual{,   title = {mvbcf: An R Package Implementing Multivariate Bayesian Causal Forests},   author = {Nathan McJames and Ann O'Shea and Yong Chen Goh and Andrew Parnell},   year = {2024},   note = {R package version 1.0},   url = {https://nathan-mcjames.github.io/mvbcf/}, }"},{"path":"https://nathan-mcjames.github.io/mvbcf/index.html","id":"mvbcf-","dir":"","previous_headings":"","what":"An R Package Implementing Multivariate Bayesian Causal Forests","title":"An R Package Implementing Multivariate Bayesian Causal Forests","text":"Welcome mvbcf R package! R package implements Multivariate Bayesian Causal Forest model introduced McJames et al., 2024: McJames, N., O’Shea, ., Goh, Y. C. & Parnell, . (2024). Bayesian causal forests multivariate outcomes: Application Irish data international large scale education assessment. Journal Royal Statistical Society Series : Statistics Society, 1-23. https://doi.org/10.1093/jrsssa/qnae049. See details installation. worked examples quick-start guides showing use package, check vignettes materials. questions, suggestions, queries, please reach mcjamesnathan@yahoo.ie.","code":""},{"path":"https://nathan-mcjames.github.io/mvbcf/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"An R Package Implementing Multivariate Bayesian Causal Forests","text":"can install development version mvbcf following:","code":"if (!require(\"devtools\")) {   install.packages(\"devtools\") } install_github(\"Nathan-McJames/mvbcf\") #Or to install vignettes with the package as well: #install_github(\"Nathan-McJames/mvbcf\", build_vignettes = TRUE)"},{"path":"https://nathan-mcjames.github.io/mvbcf/reference/run_mvbcf.html","id":null,"dir":"Reference","previous_headings":"","what":"The main function for fitting multivariate bcf — run_mvbcf","title":"The main function for fitting multivariate bcf — run_mvbcf","text":"main function fitting multivariate bcf","code":""},{"path":"https://nathan-mcjames.github.io/mvbcf/reference/run_mvbcf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The main function for fitting multivariate bcf — run_mvbcf","text":"","code":"run_mvbcf(   X_con,   y,   Z,   X_mod,   X_con_test = X_con,   X_mod_test = X_mod,   alpha = 0.95,   beta = 2,   alpha_tau = 0.25,   beta_tau = 3,   sigma_mu = diag((1)^2/n_tree, ncol(y)),   sigma_tau = diag((1)^2/n_tree_tau, ncol(y)),   v_0 = ncol(y) + 2,   sigma_0 = diag(1, ncol(y)),   n_iter = 1000,   n_tree = 50,   n_tree_tau = 20,   min_nodesize = 1 )"},{"path":"https://nathan-mcjames.github.io/mvbcf/reference/run_mvbcf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The main function for fitting multivariate bcf — run_mvbcf","text":"X_con control variables used mu trees y outcome variable/s Z treatment indicator X_mod effect moderators used tau trees X_con_test control variables used mu trees (test data) X_mod_test effect moderators used tau trees (test data) alpha alpha parameter tree prior mu trees beta beta parameter tree prior mu trees alpha_tau alpha parameter tree prior tau trees beta_tau beta parameter tree prior tau trees sigma_mu prior terminal node parameters mu trees sigma_tau prior terminal node parameter tau trees v_0 Prior degrees freedom inverse-wishart distribution sigma_0 scale matrix prior inverse-wishart distribution n_iter number MCMC iterations n_tree number mu trees n_tree_tau number tau trees min_nodesize Moves resulting nodes fewer observations rejected","code":""},{"path":"https://nathan-mcjames.github.io/mvbcf/reference/run_mvbcf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"The main function for fitting multivariate bcf — run_mvbcf","text":"list model outputs","code":""}]
